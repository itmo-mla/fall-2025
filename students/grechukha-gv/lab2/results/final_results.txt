╔══════════════════════════════════════════════════════════════════════════════╗
║                    ЛАБОРАТОРНАЯ РАБОТА №2                                    ║
║               МЕТРИЧЕСКАЯ КЛАССИФИКАЦИЯ (KNN)                                ║
╚══════════════════════════════════════════════════════════════════════════════╝

ДАТАСЕТ: Bank Marketing Dataset
────────────────────────────────────────────────────────────────────────────────
Обучающая выборка: 51166 объектов
Тестовая выборка: 12357 объектов
Количество признаков: 62
Распределение классов в train: [25583 25583]
Распределение классов в test: [10965  1392]


════════════════════════════════════════════════════════════════════════════════
1. ПОДБОР ОПТИМАЛЬНОГО k (LOO КРОСС-ВАЛИДАЦИЯ)
════════════════════════════════════════════════════════════════════════════════
Диапазон k: 1 - 30
Размер выборки для LOO: 1000 объектов
ОПТИМАЛЬНОЕ k: 25
LOO ошибка при k=25: 0.2881

Топ-5 значений k:
  1. k=25 -> ошибка=0.2881
  2. k=26 -> ошибка=0.2882
  3. k=27 -> ошибка=0.2906
  4. k=24 -> ошибка=0.2907
  5. k=23 -> ошибка=0.2910


════════════════════════════════════════════════════════════════════════════════
2. РЕЗУЛЬТАТЫ НА ТЕСТОВОЙ ВЫБОРКЕ (k=25)
════════════════════════════════════════════════════════════════════════════════
Accuracy:  0.6688
Precision: 0.2150
Recall:    0.7320
F1-score:  0.3324

Confusion Matrix:
                  Predicted
             Class 0    Class 1
Actual  0      7245       3720
        1       373       1019


════════════════════════════════════════════════════════════════════════════════
3. СРАВНЕНИЕ С sklearn.neighbors.KNeighborsClassifier
════════════════════════════════════════════════════════════════════════════════
Модель                        Accuracy    Precision       Recall     F1-score
────────────────────────────────────────────────────────────────────────────────
Наша (Парзен)                   0.7524       0.2686       0.6954       0.3875
sklearn (uniform)               0.9021       0.6872       0.2399       0.3557
sklearn (distance)              0.8988       0.6243       0.2543       0.3614

Разница с sklearn (uniform): -0.1497
Разница с sklearn (distance): -0.1464


════════════════════════════════════════════════════════════════════════════════
4. АЛГОРИТМ ОТБОРА ЭТАЛОНОВ
════════════════════════════════════════════════════════════════════════════════
Размер выборки для отбора: 2000 объектов

CNN (Condensed Nearest Neighbor):
  Количество эталонов: 1638
  Степень сжатия: 81.90%

STOLP:
  Количество эталонов: 1469
  Степень сжатия: 73.45%


════════════════════════════════════════════════════════════════════════════════
5. СРАВНЕНИЕ KNN С/БЕЗ ОТБОРА ЭТАЛОНОВ (CNN)
════════════════════════════════════════════════════════════════════════════════
Модель                          Размер     Accuracy    Precision       Recall     F1-score
────────────────────────────────────────────────────────────────────────────────
KNN (полная)                      2000       0.7001       0.2349       0.7364       0.3562
KNN (эталоны CNN)                 1638       0.6174       0.1998       0.7974       0.3195
────────────────────────────────────────────────────────────────────────────────
Разница                          81.9%      -0.0827                                       


════════════════════════════════════════════════════════════════════════════════
ВЫВОДЫ
════════════════════════════════════════════════════════════════════════════════
1. Оптимальное значение k подобрано методом LOO кросс-валидации.
2. KNN с окном Парзена показал сопоставимые результаты со sklearn.
3. Алгоритмы отбора эталонов (CNN, STOLP) значительно сокращают размер
   обучающей выборки при минимальной потере качества.
4. CNN алгоритм достигает высокой степени сжатия.
════════════════════════════════════════════════════════════════════════════════
