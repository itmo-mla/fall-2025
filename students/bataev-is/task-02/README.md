## Лабораторная работа №2 — Метрическая классификация (Iris)

### 1) Датасет

- **Датасет**: `iris.csv` (150 объектов).
- **Признаки**: 4 числовых.
- **Классы**: 3 (`setosa`, `versicolor`, `virginica`).
- **Инструменты**:
  - анализ/загрузка — **pandas**
  - реализация алгоритмов — **numpy**
  - прогресс-бары — `tqdm` (опционально)
  - графики — `matplotlib` (опционально)

---

### 2) KNN + окно Парзена переменной ширины

Для запроса \(x\) считаем расстояния до объектов обучающей выборки \(d_i = \lVert x - x_i \rVert\), сортируем, берём \(k\) ближайших.

**Переменная ширина окна**:

\[
h(x) = d_{(k)} \quad\text{(расстояние до k-го соседа)}
\]

**Гауссово ядро**:

\[
K(u) = \exp(-\tfrac{1}{2}u^2)
\]

**Взвешенное голосование**:

\[
w_i = K\!\left(\frac{d_i}{h(x)}\right),
\quad
\hat{y}(x)=\arg\max_{c}\sum_{i \in N_k(x)} w_i \cdot [y_i = c]
\]

Это реализовано в `model.py` классом `KNNParzenClassifier` (numpy-only).

---

### 3) Подбор параметра k методом скользящего контроля (LOO)

Используется **Leave-One-Out** на train-части:
- каждый объект по очереди считается тестовым
- классифицируется по остальным \(N-1\) объектам
- ошибка усредняется

Эмпирический риск:

\[
R(k) = \frac{1}{N}\sum_{i=1}^{N} [\hat{y}_{-i}(x_i) \ne y_i]
\]

График риска по \(k\): `risk_vs_k.png`.

---

### 4) Обоснование выбора параметров

- **Выбор \(k\)** делается минимизацией \(R(k)\) по LOO (см. график).
- **Переменная ширина окна** (через \(d_{(k)}\)) адаптируется к плотности данных:
  - в плотных областях окно меньше
  - в разреженных — больше
  - это снижает чувствительность к фиксированному bandwidth.

---

### 5) Сравнение с эталонной реализацией

В `main.py` добавлено сравнение с `sklearn.neighbors.KNeighborsClassifier` (если установлен).

---

### 6) Алгоритм отбора эталонов (прототипов)

Реализованы варианты:

- **CNN (Condensed Nearest Neighbor)**: итеративно добавляет объекты, которые ошибочно классифицируются текущим набором прототипов (1-NN).
- **STOLP (упрощённый вариант)**: строит радиусы по расстоянию до ближайшего “врага” и выбирает объекты, покрывающие максимум своих.
- **Parzen-CNN**: CNN-идея, но критерий добавления — ошибка **Parzen-KNN** (с фиксированным \(k\)), чтобы конденсация соответствовала используемому классификатору.

Визуализация (PCA 2D + выделение прототипов):
- `prototypes_pca.png` — для CNN
- `stolp_prototypes_pca.png` — для STOLP

---

### 7–8) Сравнение качества KNN с и без отбора эталонов

Запуск (seed=42, test_ratio=0.2, kmax=25):

- **LOO best k**: 7  
  - LOO risk: 0.0333 (acc: 0.9667)
- **Parzen-KNN (без отбора)**: test acc = **0.9667**
- **CNN (как в классическом задании)**:
  - **Variant A**: CNN-прототипы + Parzen-KNN (с переподбором k на прототипах): 17/120 прототипов, best k = 5, test acc = **0.6667**
  - (контроль) **CNN baseline**: 1-NN на CNN-прототипах: test acc = **0.8667**
- **Улучшенный вариант**:
  - **Variant B (Parzen-CNN)**: прототипы под Parzen-KNN: 32/120 прототипов, \(k=7\), test acc = **0.9000**
- **STOLP**: 9/120 прототипов, *с переподбором k на прототипах* best k = 1, test acc = **0.9667**

**Почему “CNN + Parzen-KNN” может давать низкую точность**: классический CNN оптимизирует сохранение **1-NN** решения. Parzen-KNN с переменной шириной окна \(h=d_{(k)}\) чувствителен к **плотности** выборки, а конденсация плотность меняет — отсюда деградация.  

**Правка**: чтобы честно сравнить KNN “с/без” отбора эталонов, добавлен вариант **Parzen-CNN**, который добавляет объекты, ошибочно классифицируемые текущим набором прототипов именно Parzen-KNN (фиксированный \(k\)).  

Дополнительно: после отбора эталонов \(k\) часто нужно **подбирать заново**, т.к. он влияет и на число соседей, и на ширину окна.

После этой правки STOLP дал сильное сжатие (9 прототипов вместо 120) **без потери точности на test**. CNN в этой реализации сжимает иначе и теряет accuracy заметнее.

---

### 9) Как запустить

Активировать окружение:

```bash
source /home/noru/Documents/ITMO_SUBJECTS/DL/.venv/bin/activate
```

Установить зависимости (если нужно):

```bash
pip install -U pandas tqdm matplotlib scikit-learn
```

Запуск:

```bash
python /home/noru/Documents/ITMO_SUBJECTS/fall-2025/students/bataev-is/task-02/source/main.py --kmax 25 --test_ratio 0.2 --seed 42
```

---

### Файлы

- `main.py`: pandas EDA, стандартизация, LOO-подбор \(k\), оценка на test, сравнение с sklearn (опционально), отбор эталонов, сохранение графиков.
- `model.py`: numpy-only реализация расстояний, Parzen-KNN, LOO, CNN/STOLP, PCA-2D.
- `nn_utils.py`: вспомогательные функции (не критично для этой лабораторной).
