# Лабораторная работа №1. Линейная классификация

## Описание

Реализация линейного классификатора с использованием стохастического градиентного спуска (SGD) с инерцией, L2 регуляризацией и квадратичной функцией потерь.

## Датасет

**Breast Cancer Wisconsin** - стандартный датасет для бинарной классификации из sklearn:

- Количество признаков: 30
- Размер обучающей выборки: 455
- Размер тестовой выборки: 114
- Классы: {-1, 1} (доброкачественная / злокачественная опухоль)

## Реализованные методы

### Класс `LinearClassifier`

**Основные возможности:**

1. **Методы оптимизации:**

   - Стохастический градиентный спуск (SGD) с momentum
   - Метод скорейшего спуска (Steepest Descent) с оптимальным выбором шага

2. **Стратегии инициализации весов:**

   - `random` - случайная инициализация
   - `correlation` - инициализация пропорционально корреляции признаков с целевой переменной

3. **Стратегии предъявления объектов:**

   - `random` - случайный порядок
   - `margin` - по модулю отступа (сначала сложные примеры)

## Результаты экспериментов

### 1. SGD с инерцией (Momentum)

**Гиперпараметры:**

- Learning rate: 0.003
- Momentum: 0.3
- Lambda (L2): 0.1
- Batch size: 32
- Epochs: 50

**Результат:** Accuracy = **96.49%**

![Функция потерь SGD (Random Init)](images/LF_random.png)
_График функции потерь при случайной инициализации (Train vs Test)_

![Отступы после обучения SGD](images/Margin_random.png)
_Распределение отступов после обучения SGD с momentum_

### 2. Метод скорейшего спуска

**Результат:** Accuracy = **95.61%**

![Функция потерь Steepest Descent](images/LF_baseline.png)
_Функция потерь при методе скорейшего спуска_

![Отступы Steepest Descent](images/Margin_baseline.png)
_Распределение отступов после метода скорейшего спуска_

### 3. Влияние инициализации

| Метод инициализации | Accuracy   |
| ------------------- | ---------- |
| Random              | 95.61%     |
| Correlation         | 96.49% |

![Сравнение инициализаций (Loss)](images/LF_corr.png)
_Сравнение функций потерь: Random vs Correlation Init_

![Отступы Correlation Init](images/Margin_corr.png)
_Распределение отступов при корреляционной инициализации_

### 4. Порядок предъявления объектов

| Стратегия           | Accuracy |
| ------------------- | -------- |
| Random              | 95.61%   |
| Margin (hard first) | 94.74%   |

![Сравнение стратегий предъявления (Loss)](images/LF_margin.png)
_Сравнение функций потерь: Random vs Margin Presentation_

![Отступы Margin Presentation](images/Margin_margin.png)
_Распределение отступов при предъявлении по margin_

### 5. Мультистарт (10 запусков)

**Best Loss:** 0.2492  
**Best Accuracy:** **98.25%**

![Мультистарт - функция потерь](images/LF_multi.png)
_10 запусков с разными случайными инициализациями (красная линия - лучший запуск)_

![Мультистарт - отступы](images/Margin_multi.png)
_Распределение отступов лучшей модели из мультистарта_

### 6. Сравнение с sklearn

| Модель              | Функция потерь | Accuracy         |
| ------------------- | -------------- | ---------------- |
| sklearn             | Squared Error  | 95.61%          |
| **Моя реализация** | Squared Error  | **98.25%** |

**Выводы:**

- Наша реализация показывает результаты **сопоставимые или лучше** sklearn
- Правильный подбор гиперпараметров критичен для обеих реализаций
- Корреляционная инициализация дает преимущество
