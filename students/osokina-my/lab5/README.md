# Лабораторная работа №5 — Логистическая регрессия

Проект реализует логистическую регрессию с методами Ньютона–Рафсона и IRLS, а также сравнивает результаты с эталонной реализацией из `sklearn` на датасете Breast Cancer Wisconsin.

## Теоретические основы

Логистическая регрессия решает задачу бинарной классификации, моделируя вероятность принадлежности классу через сигмоиду:

$$P(y=1|x) = \sigma(w^T x) = \frac{1}{1 + \exp(-w^T x)}.$$

Обучение сводится к минимизации логистической функции потерь. Метод Ньютона–Рафсона использует градиент и гессиан для итеративного обновления весов, а метод IRLS решает на каждом шаге взвешенную задачу наименьших квадратов. Для вычисления псевдообратной матрицы применяется SVD с отсечением малых сингулярных значений.

## Краткое описание реализации

- Данные масштабируются MinMaxScaler, метки переводятся в {-1, 1}.
- В `logistic_regression.py` реализованы два решателя: Newton–Raphson и IRLS.
- В `linear_regression.py` реализовано устойчивое решение систем через SVD.
- В `main.ipynb` выполнено обучение, оценка метрик и сравнительные таблицы.

## Результаты

Качество оценивалось на тестовой выборке (30%). Примерные метрики:

| Метод | Accuracy | Precision | Recall | F1-score |
|-------|----------|-----------|--------|----------|
| Newton-Raphson | 0.930 | 0.935 | 0.930 | 0.931 |
| IRLS | 0.947 | 0.947 | 0.947 | 0.947 |
| sklearn | 0.965 | 0.966 | 0.965 | 0.965 |

## Вывод

IRLS показывает более стабильные результаты по сравнению с чистым Ньютона–Рафсоном и приближается к качеству эталонной реализации `sklearn`. Метод Ньютона–Рафсона чувствителен к численным эффектам, поэтому для практического использования предпочтительнее IRLS либо готовые реализации библиотек.

## Примечания

- Метки классов преобразуются из {0, 1} в {-1, 1}.
- Для стабилизации вычислений используется регуляризация гессиана и устойчивая функция сигмоида.
