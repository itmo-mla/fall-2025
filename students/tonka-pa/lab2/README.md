# Отчет по лабораторной работе: kNN с переменной шириной окна (оценка методом Парзена)

## Краткое описание проекта
Проект посвящен реализации и исследованию алгоритма k-ближайших соседей с переменной шириной окна Парзена для задачи классификации. В рамках работы:
- выбран и подготовлен датасет для классификации (загрузка и хранение в `datasets/`);
- реализован собственный kNN с окном переменной ширины Парзена, поддерживающий различные ядра, а также реализующий отбор прототипов;
- выполнен подбор параметра `k` через LOO и/или кросс-валидацию с построением графиков эмпирического риска;
- проведено сравнение с реализацией kNN в scikit-learn;
- реализованы и исследованы алгоритмы отбора прототипов (ENN, STOLP, OSS);
- подготовлены визуализации границ решений и сравнительные таблицы различных метрик.

В качестве датасета для экспериментов был выбран набор данных о пациентах, среди которых есть больные Альцгеймером. [Ссылка на датасет](https://www.kaggle.com/datasets/rabieelkharoua/alzheimers-disease-dataset). Задача в датасете является обычной бинарной классификацией. В данных 34 признака, за исключением целевого, из которых информативных - 32.

## Структура проекта
```
.
├── datasets
│   ├── alzheimers_disease_data.csv
├── experiments
│   ├── __init__.py
│   ├── experiments.py
│   ├── helpers.py
│   └── main.py
├── notebooks
│   └── knn.ipynb
├── resources.txt
├── results
│   ├── epanechnikov
│   └── gaussian
└── src
    ├── __init__.py
    ├── k_param_optim.py
    ├── knn_model.py
    └── utils
        ├── __init__.py
        └── utils.py
```

## Назначение директорий и файлов
- `datasets/` — хранение исходных данных для экспериментов.
  - `alzheimers_disease_data.csv` — основной датасет для классификации.
- `src/` — основная реализация алгоритмов.
  - `knn_model.py` — реализация кастомного класса kNN с ядрами, окном Парзена, LOO, прототипным отбором. Включает также sklearn-аналог кастомного класса для проведения сравнения.
  - `k_param_optim.py` — оптимизация параметра `k` (CV/LOO) с построением кривых эмпирического риска.
  - `utils/` — вспомогательные функции для экспериментов и визуализаций.
    - `utils.py` — загрузка датасета, метрики, графики границ решений, сравнение моделей.
- `experiments/` — запуск и оркестрация экспериментов.
  - `experiments.py` — основной пайплайн экспериментов (подбор `k`, прототипы, сравнение, визуализации).
  - `helpers.py` — утилиты для препроцессинга, запуска кейсов, формирования имен файлов и визуализаций.
  - `main.py` — CLI-точка входа (`python -m experiments.main`).
- `results/` — сохраненные результаты экспериментов (графики, таблицы, визуализации) по ядрам.
  - `epanechnikov/`, `gaussian/`, `...` — результаты для соответствующих ядер.

## Ключевые элементы кода

### Core-функционал

Основной код работы содержится в директории `src/`. В ней лежат реализации кастомных классов, функций для подбора параметров и отбора прототипов, а также ряд вспомогательных функций, используемых в экспериментах. 

- `src/knn_model.py`
  - `KNearestNeighbors` — основной класс собственной реализации kNN с ядерным взвешиванием через окно Парзена и возможностью выбора Lp-нормы. Хранит обучающую выборку и набор прототипов, считает расстояния и выполняет (*взвешенное*) голосование.
  - `.predict_labels_vect` — векторизованная (оптимизированная) версия голосования. Для каждого объекта берет `(k+1)` ближайших соседей, задает ширину окна `h` как расстояние до `(k+1)`-го соседа, вычисляет веса с помощью заданного ядра и агрегирует их по классам. Точки с равными максимумами разрешаются через ближайшего соседа (tie-breaking).
  - `.leave_one_out` — LOO-оценка качества для диапазона `k`. Считает матрицу расстояний в пределах reference-подмножества (обычно весь train), исключает диагональ и строит кривую эмпирического риска. Самая вычислительно эффективная реализация LOO, однако не поддерживает no-leakage оценку именно из-за ограничений выбранной реализации.
  - `.select_prototypes` — единая точка для отбора прототипов. Поддерживает методы `enn`, `stolp`, `oss`, работу с подмножеством кандидатов, различные стратегии обновления (`replace/union/intersect/none`). Обычно сохраняет подмножество прототипов в виде массива индексов, но может с помощью флага `inplace=True` заменять тренировочную выборку на соответствующее подмножество прототипов.
  - Дополнительно: 
    - набор ядер (`uniform`, `triangular`, `epanechnikov`, `gaussian`, и т.д.);
    - `SklearnParzenKNN` — адаптер над `sklearn.neighbors KNeighborsClassifier` с пользовательским ядром для оценки весов.
- `src/k_param_optim.py`
  - `optimize_k_with_cv` — кросс-валидационный подбор `k` с оптимизацией по скорости: на каждом фолде один раз считаются расстояния и топ-`(k_max+1)` соседей, затем для всех `k` используются кэшированные для каждого фолда предсказания и матрицы расстояний. Поддерживает последовательный прототипный отбор на фолдах и построение графиков эмпирического риска.
  - `optimize_k_with_loo` — честный LOO-подбор `k` с блоковой обработкой фолдов для экономии памяти. Реализован как концепт, в тестировании применялся один раз для случая без отбора прототипов, потому что LOO сам по себе очень вычислительно затратный подход к оценке моделей.
- `src/utils/utils.py`
  - `check_for_alzheimers_dataset` — загрузка/проверка датасета (Kaggle) и сохранение в `datasets/`.
  - `score_knn` — кросс-валидационные метрики (accuracy, f1, precision, recall) и оценка среднего времени предсказания для одного инстанса.
  - `plot_decision_boundaries` — визуализация границ решений (в т.ч. с прототипами). Т.к. задача является недвумерной, для визуализации границы принятия решения был использован 2D-срез данных с помощью PCA. 
  - `compare_models` — сводные таблицы для сравнения разных вариантов моделей и прототипов.

### Ядра

Кастомный класс kNN поддерживает использование следующих ядер:
- `uniform (0)` — стандартный kNN. Теоретическое ядро равно $\frac{1}{2}$ в области определения, однако для взвешенного голосования в данном случае значение константы роли не играет, 
$$
K_{\text{uniform}}(r) =
\begin{cases}
1, & |r| \le 1 \\
0, & |r| > 1
\end{cases}
$$

- `inverse (1)` — по определению ядром не является, но для взвешенного голосования подходит, 
$$
K_{\text{inverse}}(r) = \frac{1}{r + \epsilon}
$$

- `triangular (2)` — треугольное ядро, оно просто треугольное,
$$
K_{\text{triangular}}(r) = \max\!\left(0,\, 1 - |r|\right)
$$
- `epanechnikov (3)` — епанечниково ядро, также известное как параболическое ядро. Оптимпальное ядро в терминах MSE-оценки, но это свойство актуально больше для ядерной оценки плотности, чем для задачи взвешенной классификации,
$$
K_{\text{Epanechnikov}}(r) = \max\!\left(0,\, 1 - r^2\right)
$$
- `gaussian (4)` — гауссово (нормальное) ядро, является бесконечно гладки. Теоретическое ядро, используемое в ядерной оценке плотности, содержит нормализующую константу $2\pi^{-\frac{1}{2}}$, что опять же не очень актуально для взвешенного голосования, где все элементы будут взвешенны на одну и ту же константу. В задаче взвешенной классификации важен относительный, а не абсолютный порядок наблюдений,  
$$
K_{\text{Gaussian}}(r) = \exp\!\left(-\tfrac{1}{2} r^2\right)
$$
- `tricube (5)` — трикубическое ядро, непрерывное и имеет две непрерывные производные (тоже важно в другой задаче, но все же),
$$
K_{\text{tricube}}(r) =
\max\!\left(0,\, \left(1 - |r|^3\right)^3\right)
$$

### Прототипирование

В рамках класса `KNearestNeighbors` реализованы 3 алгоритма прототипирования. Скажем о каждом пару слов.
- **ENN (Edited Nearest Neighbor)** — метод направлен на очистку выборки от шумовых объектов и сглаживание границ классов. Алгоритм удаляет те точки, класс которых отличается от мажоритарного класса их ближайших соседей, что позволяет убрать выбросы и упростить структуру решающего правила.
- **OSS (One-Sided Selection)** — алгоритм предназначен для работы с несбалансированными данными путем агрессивного сокращения мажоритарного класса при полном сохранении объектов миноритарного. Он комбинирует последовательный отбор граничных эталонов с последующим удалением связей Томека (Tomek links) для создания буферной зоны между классами.
- **STOLP (Алгоритм отбора типичных объектов)** — метод фокусируется на минимизации обучающей выборки без потери качества классификации за счет использования понятия отступа (margin). Алгоритм сначала отсеивает объекты с отрицательным отступом как неинформативные, а затем итеративно добавляет наиболее полезные (типичные) эталоны, пока не будет достигнута безошибочная классификация обучающего множества.

Методы прототипирования вызываются для инстанса класса путем вызова метода `.select_prototypes`. Данный метод по своей реализации позволяет последовательное применение алгоритмов прототипирования.

### Эксперименты

Логика проведения экспериментов вынесена в отдельную директорию `experiments/`. В ней лежат реализации последовательных тестов кастомной модели kNN с различными ядрами, со сбором метрик и визуализаций работы алгоритмов отбора прототипов и подбора параметра `k`. Множество ядер для теста модели можно задать отдельным аргументов `--kernels` при запуске экспериментов. Задавать ядра можно как строкой (например `epanechnikov`), так и индексом (индексы от 0 до количества реализованных ядер, смотрите список ядер выше). Тест можно запускать сразу для нескольких ядер, передав после флага `--kernels` все интересующие ядра. Тесты для них будут запущены в последовательности, в которой они были заданы в аргументе. Если не передавать данный аргумент, тесты будут запущены для всех доступных ядер последовательно. Далее идет описание структуры директории `experiments/`.

- `experiments.py` запускает полный экспериментальный цикл: чтение данных, препроцессинг, подбор `k`, оценка качества с/без прототипного отбора, сравнение со scikit-learn и построение визуализаций.
- `helpers.py` содержит утилиты для подготовки данных (выделение типов признаков, препроцессор), нормализации списка ядер, форматирования имен файлов и запуска отдельных экспериментальных сценариев (default/enn/oss/stolp/комбинации).
- `main.py` — точка входа, которая вызывает загрузку датасета и `run_tests` с настройками по ядрам и выходной директории, куда будут собраны результаты работы внутрених алгоритмов и функций оценки производительности моделей.

## Анализ экспериментов

### Ядра

Была проведена серия из 6 экспериментов, по одному на каждое из доступных ядер. Еще раз о ядрах: 
- `uniform` — все объекты имеют одинаковый вес в процессе голосования;
-  `inverse` — сильное влияние ближайших соседей и очень слабое у наиболее удаленных. Из-за такого поведения функции такое "ядро" более чувствительно к выбросам в данных, а модель на его основе может легко переобучиться. По сути является soft-версией 1-NN;
-  `triangular` — вес объекта имеет линейнию зависимость от расстояния до классифицируемого объекта (буквально линейная функция в положительной полуплоскости (и нуле)). Является балансом между locality и robustness;
-  `epanechnikov` — вес объекта имеет квадратичную зависимость от расстояния. Сильный упор на близкие точки. Данное ядро чуть более локальное, чем треугольное;
-  `gaussian` — более умеренное снижение веса при увеличении расстояния по сравнению с предыдущими ядрами;
-  `tricube` — еще одно ядро с какими-то своими свойствами.

Принципиальная разница между ядрами в основном в их лоакльном поведении в диапазоне, где они положительно определены.

![kernels_vis](/students/tonka-pa/lab2/datasets/images/kernels_vis.png "Графики функций ядер")

### Предобработка

Предварительно важным для метрических моделей является масштаб данных. Т.к. параметрические модели полностью завязаны на понятии расстояния, принципиально важным является приведение всех признаков в данных к единому масштабу, чтобы избежать повышенного/доминирующего влияния одного признака над другим. В частности ядра подразумевают *стандартную* шкалу данных, поэтому все признаки, за исключением единственного категориального, были **отцентрированы и отмасштабированы на значение дисперсии выборки** (т.е. была применена `z-нормализация`). Оставшийся признак - бинарный, масштабировать его особого смысла нет.

### Паттерн экспериментов

Для каждого ядра была проведена абсолютно идентичная серия тестов и замеров. Порядок следующий:
1. **5NN** — сначала оценивалась *baseline*-модель с заданным ядром. В качестве baseline было выбраное значение параметра `k=5`.
2. **OptNN (без прототипирования)** — далее для модели с тем же ядром подбиралось оптимальное значение `k`. Диапазон значений при подборе - $[1, 50]$. Такой диапазон подобран эмпирическим путем, для всех ядер, кроме трикубического, оптимальное значение параметра было найдено на нем. Для трикубического ядра для решаемой задачи диапазон был расширен до 100, однако даже такой диапазон, вероятно, был недостаточен для нахождения настоящего оптимального значения параметра. С другой стороны, проблема для модели с трикубическим ядром найти оптимальное `k` в заданном диапазоне, когда модели с другими ядрами с этой задачей справились без проблем, говорит скорее о не лучшей пригодности ядра в рамках решаемой задачи.
3. **ENN-прототипирование** — поиск оптимального `k` с применением алгоритма прототипирования `ENN`. Подбор параметров осуществляется с помощью кросс-валидации на 30 фолдах. Причем прототипирование, как и препроцессинг, осуществляется для каждого фолда отдельно, чтобы получить более достоверную и несмещенную оценку эмпирического риска. После нахождения оптимального `k` для заданного алгоритма прототипирования осуществляется оценка качества модели по основным метрикам классификации (`F1`, `precision`, `recall`, `accuracy`) с применением заданного алгоритма прототипирования, и также с помощью кросс-валидации, но уже на 20 фолдах. Дополнительно, чтобы получить оценку скорости предсказания модели для одного наблюдения, оценивается среднее время предсказания, полученное путем осуществления предсказания на одном и том же тестовом (в рамках фолда) наборе 100 раз подряд, усредненное и нормализованное на размер тестового набора.
4. **OSS-прототипирование** — аналогично предыдущему этапу.
5. **STOLP-прототипирование** — аналогично предыдущим этапам.
6. **ENN+OSS-прототипирование** — аналогично предыдущим этапам, за исключением того, что два алгоритма применялись последовательно.
7. **5NN Sklearn** — аналогично первому шагу, но для адаптированной эталонной реализации из библиотеки Sklearn.
8. **OptNN (без прототипирования)** — аналогично второму шагу, но для адаптированной эталонной реализации из библиотеки Sklearn.
9. **Построение графиков decision boundaries** с учетом различных подмножеств прототипов, полученных различными алгоритмами.

### Результаты

Т.к. объемы всех экспериментов довольно велики, показывать графики эмпирического риска для каждого случая не представляется возможным, поэтому будет приведено лишь несколько примеров того, как выглядят выходные графики функций, использованных в экспериментах. Однако сводные таблицы результатов по каждому ядру приведены в полном объеме.

Рисунок 1. Пример графика эмпирического риска для гауссовго ядра без прототипирования с помощью LOO-оценки (data leakage, но самая быстрая реализация)
![](/students/tonka-pa/lab2/results/gaussian/loo_fast_kernel-gaussian_k-1-50_proto-no-proto.png)

Рисунок 2. Пример графика эмпирического риска для гауссовго ядра без прототипирования с помощью CV-оценки (30 фолдов)
![gaussian_no_proto_cv](/students/tonka-pa/lab2/results/gaussian/cv_risk_kernel-gaussian_k-1-50_proto-no-proto.png)

Рисунок 3. Пример графика эмпирического риска для гауссовго ядра без прототипирования с помощью LOO-оценки (без data leakage, но менее эффективная реализация)
![](/students/tonka-pa/lab2/results/gaussian/loo_fair_kernel-gaussian_k-1-50_proto-no-proto.png)

Рисунок 4. Пример графика эмпирического риска для гауссовго ядра с STOLP-прототипированием с помощью CV-оценки
![](/students/tonka-pa/lab2/results/gaussian/cv_risk_kernel-gaussian_k-1-50_proto-stolp.png)

Рисунок 5. Пример графика эмпирического риска для гауссовго ядра с ENN+OSS-прототипированием с помощью CV-оценки
![](/students/tonka-pa/lab2/results/gaussian/cv_risk_kernel-gaussian_k-1-50_proto-enn-oss.png)


Рисунок 6. Пример графика эмпирического риска для гауссовго ядра без прототипирования с помощью LOO-оценки для sklearn-реализации
![](/students/tonka-pa/lab2/results/gaussian/loo_sklearn_kernel-gaussian_k-1-50_proto-no-proto.png)

Стоит отметить следующие факты:
- кастомное решение и решение, полученное на базе адаптированного sklearn-классификатора, получилось идентичным;
- определенное смещение оценки параметра `k` из-за data leakage имеется (первые три графика);
- оценка эмпирического риска, полученная с помощью кросс-валидации на 30 фолдах (рис.2), получилась довольно близкой к LOO-честной оценке (рис.3);
- разные подвыборки прототипов приводят к разным оптимальным значениям параметра, что очевидно, но всё экспериментально подтверждается, что для выборки нет единого эталонного значения параметра.

Сводные таблицы содержат в себе собранные для каждой модели с определенным ядром метрики с каждого шага, описанного в предыдущем пункте. Результаты отсортированы по столбцу `F1`.

Таблица 1. Результаты для *gaussian kernel*
| Model                 |       F1 |   Accuracy |   Precision |   Recall |   Prediction Time (ns) |   Number of Prototypes |
|:----------------------|---------:|-----------:|------------:|---------:|-----------------------:|-----------------------:|
| enn_oss_opt_20nn      | 0.649711 |   0.715204 |    0.578374 | 0.744737 |                365.6   |                    711 |
| oss_opt_7nn           | 0.619646 |   0.639802 |    0.49573  | 0.830263 |                464.252 |                   1330 |
| sklearn_22nn          | 0.617188 |   0.784086 |    0.8302   | 0.494737 |                710.573 |                   2149 |
| default_fast_loo_22nn | 0.617188 |   0.784086 |    0.8302   | 0.494737 |                600.771 |                   2149 |
| default_5nn           | 0.612748 |   0.755677 |    0.70236  | 0.548684 |                553.378 |                   2149 |
| sklearn_5nn           | 0.612748 |   0.755677 |    0.70236  | 0.548684 |                612.31  |                   2149 |
| default_cv_26nn       | 0.602899 |   0.781265 |    0.843549 | 0.473684 |                612.307 |                   2149 |
| default_fair_loo_26nn | 0.602899 |   0.781265 |    0.843549 | 0.473684 |                626.902 |                   2149 |
| enn_opt_18nn          | 0.534219 |   0.759887 |    0.852916 | 0.392105 |                500.635 |                   1459 |
| stolp_opt_44nn        | 0.513098 |   0.756624 |    0.869001 | 0.365789 |                458.219 |                    507 |

Таблица 2. Результаты для *uniform kernel*
| Model                 |       F1 |   Accuracy |   Precision |   Recall |   Prediction Time (ns) |   Number of Prototypes |
|:----------------------|---------:|-----------:|------------:|---------:|-----------------------:|-----------------------:|
| enn_oss_opt_20nn      | 0.645694 |   0.710562 |    0.573036 | 0.743421 |                367.117 |                    711 |
| oss_opt_16nn          | 0.627503 |   0.641615 |    0.499148 | 0.851316 |                506.678 |                   1330 |
| default_fair_loo_24nn | 0.614347 |   0.784986 |    0.840303 | 0.488158 |                622.498 |                   2149 |
| default_fast_loo_24nn | 0.614347 |   0.784986 |    0.840303 | 0.488158 |                613.053 |                   2149 |
| default_cv_24nn       | 0.614347 |   0.784986 |    0.840303 | 0.488158 |                613.1   |                   2149 |
| default_5nn           | 0.612748 |   0.755677 |    0.70236  | 0.548684 |                554.477 |                   2149 |
| sklearn_5nn           | 0.612748 |   0.755677 |    0.70236  | 0.548684 |                624.673 |                   2149 |
| sklearn_25nn          | 0.599931 |   0.780335 |    0.837103 | 0.472368 |                709.835 |                   2149 |
| enn_opt_18nn          | 0.52795  |   0.758004 |    0.850804 | 0.385526 |                501.866 |                   1459 |
| stolp_opt_44nn        | 0.501876 |   0.753362 |    0.869866 | 0.355263 |                437.101 |                    507 |

Таблица 3. Результаты для *inverse kernel*
| Model                 |       F1 |   Accuracy |   Precision |   Recall |   Prediction Time (ns) |   Number of Prototypes |
|:----------------------|---------:|-----------:|------------:|---------:|-----------------------:|-----------------------:|
| enn_oss_opt_20nn      | 0.649617 |   0.715204 |    0.578199 | 0.744737 |                378.661 |                    711 |
| oss_opt_7nn           | 0.619646 |   0.639802 |    0.49573  | 0.830263 |                451.337 |                   1330 |
| sklearn_22nn          | 0.619354 |   0.785016 |    0.831731 | 0.497368 |                712.288 |                   2149 |
| default_fast_loo_22nn | 0.619354 |   0.785016 |    0.831731 | 0.497368 |                621.736 |                   2149 |
| default_5nn           | 0.612748 |   0.755677 |    0.70236  | 0.548684 |                555.128 |                   2149 |
| sklearn_5nn           | 0.612748 |   0.755677 |    0.70236  | 0.548684 |                544.795 |                   2149 |
| default_cv_26nn       | 0.604626 |   0.782195 |    0.846453 | 0.475    |                614.121 |                   2149 |
| default_fair_loo_26nn | 0.604626 |   0.782195 |    0.846453 | 0.475    |                606.32  |                   2149 |
| enn_opt_18nn          | 0.533867 |   0.759887 |    0.852932 | 0.392105 |                502.734 |                   1459 |
| stolp_opt_44nn        | 0.512227 |   0.756624 |    0.872334 | 0.364474 |                432.464 |                    507 |

Таблица 4. Результаты для *triangular kernel*
| Model                 |       F1 |   Accuracy |   Precision |   Recall |   Prediction Time (ns) |   Number of Prototypes |
|:----------------------|---------:|-----------:|------------:|---------:|-----------------------:|-----------------------:|
| enn_oss_opt_23nn      | 0.65483  |   0.724039 |    0.590654 | 0.738158 |                357.738 |                    711 |
| oss_opt_30nn          | 0.631867 |   0.649117 |    0.503487 | 0.851316 |                519.729 |                   1330 |
| sklearn_28nn          | 0.628424 |   0.785929 |    0.815411 | 0.517105 |                740.586 |                   2149 |
| default_fast_loo_28nn | 0.628424 |   0.785929 |    0.815411 | 0.517105 |                627.718 |                   2149 |
| default_fair_loo_42nn | 0.625154 |   0.789663 |    0.84235  | 0.501316 |                676.025 |                   2149 |
| default_cv_45nn       | 0.623982 |   0.790594 |    0.852865 | 0.496053 |                674.214 |                   2149 |
| default_5nn           | 0.595423 |   0.736609 |    0.657421 | 0.551316 |                572.053 |                   2149 |
| sklearn_5nn           | 0.595423 |   0.736609 |    0.657421 | 0.551316 |                548.352 |                   2149 |
| stolp_opt_31nn        | 0.580475 |   0.766866 |    0.797621 | 0.457895 |                388.905 |                    507 |
| enn_opt_30nn          | 0.54209  |   0.761738 |    0.849344 | 0.401316 |                532.629 |                   1459 |

Таблица 5. Результаты для *epanechnikov kernel*
| Model                 |       F1 |   Accuracy |   Precision |   Recall |   Prediction Time (ns) |   Number of Prototypes |
|:----------------------|---------:|-----------:|------------:|---------:|-----------------------:|-----------------------:|
| enn_oss_opt_23nn      | 0.655788 |   0.724965 |    0.591159 | 0.739474 |                381.495 |                    711 |
| oss_opt_22nn          | 0.635964 |   0.653782 |    0.508488 | 0.852632 |                484.222 |                   1330 |
| sklearn_25nn          | 0.622971 |   0.782208 |    0.804943 | 0.514474 |                696.577 |                   2149 |
| default_fast_loo_25nn | 0.622971 |   0.782208 |    0.804943 | 0.514474 |                615.422 |                   2149 |
| default_fair_loo_25nn | 0.622971 |   0.782208 |    0.804943 | 0.514474 |                614.071 |                   2149 |
| default_cv_43nn       | 0.621418 |   0.7892   |    0.850658 | 0.493421 |                664.7   |                   2149 |
| default_5nn           | 0.594631 |   0.737059 |    0.659084 | 0.548684 |                559.383 |                   2149 |
| sklearn_5nn           | 0.594631 |   0.737059 |    0.659084 | 0.548684 |                552.001 |                   2149 |
| stolp_opt_37nn        | 0.580972 |   0.771063 |    0.821376 | 0.451316 |                415.054 |                    507 |
| enn_opt_30nn          | 0.540291 |   0.761738 |    0.851628 | 0.398684 |                538.796 |                   1459 |

Таблица 6. Результаты для *tricube kernel*
| Model                 |       F1 |   Accuracy |   Precision |   Recall |   Prediction Time (ns) |   Number of Prototypes |
|:----------------------|---------:|-----------:|------------:|---------:|-----------------------:|-----------------------:|
| enn_oss_opt_82nn      | 0.655712 |   0.724494 |    0.590494 | 0.740789 |                675.297 |                    711 |
| default_cv_95nn       | 0.636277 |   0.791507 |    0.832031 | 0.521053 |               1128.37  |                   2149 |
| sklearn_98nn          | 0.635569 |   0.791507 |    0.832859 | 0.519737 |               1280.36  |                   2149 |
| default_fast_loo_98nn | 0.635569 |   0.791507 |    0.832859 | 0.519737 |               1135.65  |                   2149 |
| default_fair_loo_98nn | 0.635569 |   0.791507 |    0.832859 | 0.519737 |               1136.92  |                   2149 |
| oss_opt_43nn          | 0.628323 |   0.651904 |    0.50611  | 0.831579 |                647.124 |                   1330 |
| stolp_opt_64nn        | 0.582384 |   0.763119 |    0.776569 | 0.467105 |                579.308 |                    507 |
| default_5nn           | 0.567225 |   0.705434 |    0.592605 | 0.55     |                637.884 |                   2149 |
| sklearn_5nn           | 0.567225 |   0.705434 |    0.592605 | 0.55     |                548.152 |                   2149 |
| enn_opt_84nn          | 0.538095 |   0.760787 |    0.847605 | 0.397368 |                833.485 |                   1459 |

---
