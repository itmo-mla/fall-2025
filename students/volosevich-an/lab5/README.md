# Лабораторная работа №5 (Логистическая регрессия)

Задача: реализовать функционал логистического регрессора, а также методов оптимизации второго порядка: метода Ньютона-Рафсона и IRLS. Обучить модель, сравнить с эталлоной реализацией.

## Навигация по директориям и файлам

- source - директория с файлами исходного кода;
    - logreg.py - файл с реализацией логстической регрессии с методами Ньютона-Рафсона и IRLS на numpy;
    - experiments.py - файл с различными экспериментами с моделями;

# Отчет по проделанной работе

## Выбранный датасет

Задача бинарной классификации болезни средца [https://www.kaggle.com/datasets/yasserh/heart-disease-dataset]

Датасет без пропусков.

## Реализация
- Для реализации указанного функционала, в основном использовались библиотеки numpy и pandas;

- Для подсчета метрик использовался функционал Scikit-learn, как и для разбиения выборки на тренировочную и валиадционную;

- Реализовано два метода для обучения модели в соответсвии с заданием;

- Эталонным алгоритмом выступает LogisticRegression из фреймворка scikit-learn, с методом оптимизации LBFGS.


## Ход работы

Данные для обучения были обработаны через StandardScaler. Датасет разделен на обучающую и валидационную выборки 0.8 и 0.2 от датасета соотвественно. Для каждой модели берем один random seed. 

Указанные гиперпараметры для всех моделей:
- max_iter: 1000;
- tol: 1e-6;

**Полученные метрки (сошлись у всех моделей с точностью до 4го знака):**
- Accuracy: 0.8525
- Precision: 0.8710
- Recall: 0.8438
- F1-score: 0.8571
- ROC AUC: 0.8529

**Мера косинсного сходства между полученными коэффициентами моделей:**
- NR и IRLS : 1.0000
- NR и Sklearn: 0.9999
- IRLS и Sklearn: 0.9999



## Выводы по работе

В результате выполнения лабораторной работы был реализован функционал логистического регрессора вместе с методами оптимизации Ньютона-Рафсона и IRLS. Полученная модель по результатам экспериментов практически сошлась по точности с эталонным алгоритмом из scikit-learn.

Также, было показано, что при предварительной стандартизации признаков и одинаковых условиях оптимизации реализованные методы демонстрируют совпадение основных метрик качества классификации (Accuracy, Precision, Recall, F1-score, ROC AUC) с точностью до округления (4х знаков после запятой). Дополнительно, высокие значения косинусного сходства между векторами коэффициентов моделей подтверждают, что методы Ньютона–Рафсона и IRLS сходятся к одному и тому же решению и являются математически эквивалентными для задачи логистической регрессии. 

Таким образом, результаты лабораторной работы подтверждают корректность реализации логистической регрессии и демонстрируют практическую эквивалентность методов оптимизации второго порядка при соблюдении условий численной стабильности задачи.
