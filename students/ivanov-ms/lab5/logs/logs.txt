Running data pipeline...
Data pipeline finished in 0.44 sec

Training our Logistic Regression (Newton-Raphson)...
-- NR iter 1: 120.08304533991998
-- NR iter 2: 2.0412382253216577
-- NR iter 3: 2.0033877000335827
-- NR iter 4: 1.9680763961708199
-- NR iter 5: 1.9352239776792202
-- NR iter 6: 1.9047883676823898
-- NR iter 7: 1.8767660351117659
-- NR iter 8: 1.8511937446544524
-- NR iter 9: 1.8281519195983094
-- NR iter 10: 1.8077698902495152
-- NR iter 11: 1.790233456235541
-- NR iter 12: 1.7757954002072653
-- NR iter 13: 1.7647898836635052
-- NR iter 14: 1.7576520783326215
-- NR iter 15: 1.7549450073433452
-- NR iter 16: 1.7573964911526418
-- NR iter 17: 1.7659504564801878
-- NR iter 18: 1.7818388371459524
-- NR iter 19: 1.8066829220457603
-- NR iter 20: 1.8426355900524078
-- NR iter 21: 1.8925743488161872
-- NR iter 22: 1.9603309061830674
-- NR iter 23: 2.0508125774021533
-- NR iter 24: 2.169233115334655
-- NR iter 25: 2.3154522623596625
-- NR iter 26: 2.454956160266469
-- NR iter 27: 2.4766773535478093
-- NR iter 28: 2.8263992796072803
-- NR iter 29: 2.2299759537512087
-- NR iter 30: 1.9622766213912803
-- NR iter 31: 1.7013055960796435
-- NR iter 32: 1.4949314447097537
-- NR iter 33: 1.3147824532206858
-- NR iter 34: 1.1594681219835299
-- NR iter 35: 1.021179267662846
-- NR iter 36: 0.8705797306496259
-- NR iter 37: 0.775597264866587
-- NR iter 38: 0.6932872270378718
-- NR iter 39: 0.6269942963360827
-- NR iter 40: 0.5650218772835882
-- NR iter 41: 0.517222328902187
-- NR iter 42: 0.46917930804277974
-- NR iter 43: 0.4333694541847752
-- NR iter 44: 0.3957695377579602
-- NR iter 45: 0.367895799223778
-- NR iter 46: 0.33769095482999895
-- NR iter 47: 0.315286691060909
-- NR iter 48: 0.29042722605855614
-- NR iter 49: 0.27198450155682846
-- NR iter 50: 0.2511514249333483
-- NR iter 51: 0.23571447389009687
-- NR iter 52: 0.21803272668396234
-- NR iter 53: 0.20496176480643205
-- NR iter 54: 0.18982084025849613
-- NR iter 55: 0.17866222847084515
-- NR iter 56: 0.16561439844423917
-- NR iter 57: 0.15603017191721605
-- NR iter 58: 0.14473323807117935
-- NR iter 59: 0.13646202396554194
-- NR iter 60: 0.12664614172351715
-- NR iter 61: 0.11948041928519719
-- NR iter 62: 0.11092788152640323
-- NR iter 63: 0.10469987424468039
-- NR iter 64: 0.0972320565745433
-- NR iter 65: 0.09180436815761213
-- NR iter 66: 0.08527281888855792
-- NR iter 67: 0.080531835895562
-- NR iter 68: 0.07481190669901207
-- NR iter 69: 0.07066293179910181
-- NR iter 70: 0.06564906099882994
-- NR iter 71: 0.062012606199652424
-- NR iter 72: 0.05761473574012507
-- NR iter 73: 0.0544236401137368
-- NR iter 74: 0.05056444392500165
-- NR iter 75: 0.04776160391230492
-- NR iter 76: 0.04437431530719959
-- NR iter 77: 0.04191088413871838
-- NR iter 78: 0.038937574926658725
-- NR iter 79: 0.036771528091605936
-- NR iter 80: 0.03416173302521701
-- NR iter 81: 0.032256722224275516
-- NR iter 82: 0.02996632972212775
-- NR iter 83: 0.028290764987865195
-- NR iter 84: 0.026281114294818886
-- NR iter 85: 0.02480742643044831
-- NR iter 86: 0.023044565469535642
-- NR iter 87: 0.021748610510500543
-- NR iter 88: 0.02020267932811103
-- NR iter 89: 0.01906325438269576
-- NR iter 90: 0.01770796728128059
-- NR iter 91: 0.016706413396679814
-- NR iter 92: 0.015518619198892171
-- NR iter 93: 0.01463849211186627
-- NR iter 94: 0.013597796916053187
-- NR iter 95: 0.012824590842609266
-- NR iter 96: 0.011913031406063266
-- NR iter 97: 0.011233944510181252
-- NR iter 98: 0.010435703264195205
-- NR iter 99: 0.009839436215265153
-- NR iter 100: 0.009140591064053905
-- NR iter 101: 0.00861717224301282
-- NR iter 102: 0.008005475885532907
-- NR iter 103: 0.00754610842916825
-- NR iter 104: 0.007010793101072211
-- NR iter 105: 0.006607720180765663
-- NR iter 106: 0.006139324552269317
-- NR iter 107: 0.0057857101590110495
-- NR iter 108: 0.00537592572940836
-- NR iter 109: 0.00506574886120487
-- NR iter 110: 0.00470728363001369
-- NR iter 111: 0.0044352442180121895
-- NR iter 112: 0.004121701735742927
-- NR iter 113: 0.003883136954504725
-- NR iter 114: 0.0036089091005446355
-- NR iter 115: 0.003399718926626717
-- NR iter 116: 0.003159890952308971
-- NR iter 117: 0.0029764719930880246
-- NR iter 118: 0.0027667385234259436
-- NR iter 119: 0.002605925256073333
-- NR iter 120: 0.0024225160747766697
-- NR iter 121: 0.002281528727188332
-- NR iter 122: 0.002121143284102398
-- NR iter 123: 0.001997541665570568
-- NR iter 124: 0.0018572913482719994
-- NR iter 125: 0.0017489340025089693
-- NR iter 126: 0.0016262913069467417
-- NR iter 127: 0.0015312994181050778
Converged at iteration 128
Evaluation:
  Accuracy: 0.6959
  Precision: 0.9737
  Recall: 0.3692
  F1-Score: 0.5354
  AUC-ROC: 0.9498

Training our Logistic Regression (IRLS)...
-- IRLS iter 1: 120.08304533991998
-- IRLS iter 2: 24.532115711281353
-- IRLS iter 3: 5.773863217392775
-- IRLS iter 4: 2.4501433187553303
-- IRLS iter 5: 1.1615094813482314
-- IRLS iter 6: 0.5726176590039008
-- IRLS iter 7: 0.2861672186762353
-- IRLS iter 8: 0.14365300258583558
-- IRLS iter 9: 0.07228016570427666
-- IRLS iter 10: 0.036516283362733194
-- IRLS iter 11: 0.01863582387901177
-- IRLS iter 12: 0.009747891345991471
-- IRLS iter 13: 0.005387696008199332
-- IRLS iter 14: 0.0032984354066204944
-- IRLS iter 15: 0.0023155361342459702
-- IRLS iter 16: 0.0018376869719780656
-- IRLS iter 17: 0.0015799233930733493
Converged at iteration 18
Evaluation:
  Accuracy: 0.8417
  Precision: 0.8169
  Recall: 0.8589
  F1-Score: 0.8374
  AUC-ROC: 0.9493

Training Sklearn's Logistic Regression...
Evaluation:
  Accuracy: 0.7747
  Precision: 0.9578
  Recall: 0.5493
  F1-Score: 0.6982
  AUC-ROC: 0.9497

============================================================
COMPARING LOGISTIC REGRESSION IMPLEMENTATIONS
============================================================

Metrics comparison:
        Method  Test size  Accuracy  Precision    Recall        F1   ROC AUC
0    Custom NR      13500  0.695926   0.973652  0.369185  0.535371  0.949833
1  Custom IRLS      13500  0.841704   0.816927  0.858882  0.837379  0.949281
2      Sklearn      13500  0.774667   0.957812  0.549329  0.698214  0.949731