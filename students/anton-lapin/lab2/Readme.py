Лабораторная работа: Метрические методы классификации и регрессии
Описание работы
В данной лабораторной работе исследуются метрические методы классификации, в частности метод Парзена с переменной шириной окна и метод отбора эталонов (prototype learning). Работа выполнена на классическом датасете "Ирисы Фишера" (Iris dataset).

Датасет Iris
Датасет содержит 150 образцов ирисов, каждый из которых описан 4 признаками:

Длина чашелистика (sepal length)

Ширина чашелистика (sepal width)

Длина лепестка (petal length)

Ширина лепестка (petal width)

Образцы разделены на 3 класса:

0: Iris Setosa

1: Iris Versicolor

2: Iris Virginica

Реализованные методы
1. Метод Парзена переменной ширины
Реализован алгоритм классификации с использованием гауссова ядра и переменной ширины окна, где ширина окна определяется расстоянием до (k+1)-го ближайшего соседа.

2. Отбор эталонов (Prototype Learning)
Реализован жадный алгоритм отбора эталонов на основе эмпирического риска 1NN, позволяющий значительно уменьшить количество объектов для классификации без существенной потери точности.

Результаты
Эмпирический риск на исходных данных
https://source/images/EmperikRiskAllData.png

На графике показана зависимость эмпирического риска (ошибки LOO) от параметра k для метода Парзена на полной выборке. Оптимальное значение k было подобрано методом скользящего контроля.

Точность классификации на исходных данных
https://source/images/AccuracyAllData.png

Сравнение точности классификации метода Парзена и эталонной реализации KNN из sklearn на полной выборке.

Визуализация отбора эталонов в PCA пространстве
https://source/images/EmperikVisualize.png

Визуализация показывает результат отбора эталонов в двумерном PCA пространстве:

Серые точки: удалённые объекты

Цветные точки: отобранные эталоны

Эмпирический риск на эталонах
https://source/images/emperickriskEtalons.png

Зависимость эмпирического риска от k для метода Парзена на отобранных эталонах.

Точность классификации на эталонах
https://source/images/AccuracyEtalon.png

Сравнение точности классификации на отобранных эталонах методом Парзена и sklearn KNN.

Выводы
Эффективность отбора эталонов: Метод отбора эталонов позволил сократить количество объектов с 120 до ~30-40 (удаление 70-75% объектов) при сохранении точности классификации в пределах допустимого отклонения (обычно не более 2-3%).

Качество метода Парзена: Реализованный метод Парзена с переменной шириной окна показывает точность, сопоставимую с эталонной реализацией KNN из библиотеки sklearn.

Вычислительная эффективность: Использование эталонов значительно ускоряет процесс классификации, так как требуется вычислять расстояния до меньшего количества объектов.

Адаптивность метода Парзена: Метод переменной ширины окна автоматически адаптируется к локальной плотности данных, что делает его более устойчивым к выбору параметров по сравнению с методом фиксированной ширины окна.

Визуальная интерпретируемость: PCA визуализация наглядно демонстрирует, что отобранные эталоны в основном расположены на границах классов и в центрах кластеров, что соответствует теоретическим ожиданиям.

Заключение
Работа подтвердила эффективность метрических методов для задач классификации и показала, что отбор эталонов является мощным инструментом для сжатия данных без существенной потери информации. Реализованный метод Парзена переменной ширины демонстрирует хорошие результаты и может быть использован в реальных задачах машинного обучения.
