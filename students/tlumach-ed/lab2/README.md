# Лабораторная работа №2  
**Метрическая классификация (KNN + Parzen, LOO, отбор эталонов)**

---

## 1. Выбор датасета
Для экспериментов выбран датасет **Wine** из библиотеки `sklearn.datasets`.  
Причины выбора:
- компактный (178 объектов, 13 признаков, 3 класса);
- сбалансированный (примерно равное количество наблюдений по классам);
- хорошо подходит для методов метрической классификации.

 Реализация загрузки: `source/utils.py → load_default_dataset()`  
Данные стандартизируются с помощью `StandardScaler`.

---

## 2️. Реализация алгоритма KNN с методом окна Парзена (переменная ширина)
Реализован класс `KNNParzen`, поддерживающий:
- вычисление попарных расстояний (по Евклиду);
- переменную ширину окна: ширина = расстояние до (k+1)-го соседа;
- гауссово ядро:  
  \[ K(r) = exp(-2 r^2) \]
- методы `fit(X, y)` и `predict(X, k)` с интерфейсом, аналогичным `sklearn`.

 Код: `source/knn_parzen.py`

---

## 3️. Подбор параметра *k* методом скользящего контроля (LOO)
Для подбора оптимального числа соседей реализована Leave-One-Out кросс-валидация.  
Алгоритм:
- для каждого объекта исключаем его из выборки,
- классифицируем оставшимися,
- считаем долю ошибок.

 Реализация: `source/utils.py → loo_search_k()`  
 Результат подбора:  Лучший k = 31, LOO ошибка = 0.0169
 
---

## 4️. Обоснование выбора параметров и график эмпирического риска

Построен график зависимости ошибки LOO от числа соседей `k`:

![risk_vs_k](source/risk_vs_k.png)

 Интерпретация:
- При малых `k` ошибка выше (переобучение).
- Между `k ≈ 5–30` наблюдается **плато**.
- При `k ≈ 31` достигается минимум ошибки (~1.7%).

График получен функцией  
 `source/utils.py → plot_risk_vs_k()`  

---

## 5. Сравнение с эталонной реализацией KNN (`sklearn`)
Для проверки корректности и качества алгоритма проведено сравнение с библиотечным `KNeighborsClassifier`.

| Алгоритм | k | Accuracy | Комментарий |
|-----------|---|-----------|-------------|
| `KNNParzen (наш)` | 31 | **0.9831** | немного лучше |
| `sklearn.KNeighborsClassifier` | 31 | **0.9775** | эталонная реализация |

 Реализация сравнения: `source/utils.py → compare_with_sklearn()`

 Вывод: наша реализация корректна, работает не хуже эталонной.

---

## 6. Реализация алгоритма отбора эталонов
Реализованы два метода:
- **`greedy_remove`** — жадное удаление эталонов;
- **`greedy_add`** — жадное добавление эталонов.

 Код: `source/prototypes.py`  
Основная идея — удалить точки, не влияющие на границы принятия решений (LOO-ошибка не ухудшается).

В эксперименте `greedy_remove` не удалил ни одного эталона (все 178 остались),  
так как исходная ошибка уже минимальна, а `tol=1e-6` не позволяет ухудшать LOO.

---

## 7️. Визуализация результатов отбора эталонов
Для наглядности использована PCA-проекция (2D).  
Каждая точка — объект, цвет соответствует классу.

![prototypes_pca](source/prototypes_pca.png)

 Интерпретация:
- Классы Wine хорошо разделимы уже в 2D.
- Жадный алгоритм не удалил ни одного эталона → все точки отображены цветом классов.
- Если бы часть эталонов была удалена, они бы отображались пустыми кружками с обводкой.

 Реализация визуализации: `source/run_experiment.py`, блок с PCA и matplotlib.

---

## 8️. Сравнение качества KNN с и без отбора эталонов
| Вариант | Accuracy | Кол-во эталонов |
|----------|-----------|----------------|
| Полная выборка | 0.9831 | 178 |
| После жадного удаления | 0.9831 | 178 |

Вывод:  
Удаление эталонов не изменило качество классификации —  
алгоритм подтвердил, что исходная выборка уже оптимальна (нет избыточных объектов).

---

## 9️. Выводы
- Реализован KNN с методом окна Парзена переменной ширины (гауссово ядро).  
- Подбор *k* выполнен методом LOO, оптимум при `k=31`.  
- Реализация совпадает по качеству с эталонной (`sklearn`).  
- Жадный отбор эталонов корректно работает, но на данном датасете не выявил избыточных точек.  
- Построены и интерпретированы графики:
  - `risk_vs_k.png` — зависимость ошибки от числа соседей;
  - `prototypes_pca.png` — распределение классов и эталонов.
- Код организован модульно, эксперимент воспроизводим командой:
  ```bash
  python -m source.run_experiment


---




